{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")\n",
    "os.chdir(r\"src\")\n",
    "\n",
    "from Polarization.word_partisanship import *\n",
    "from GloVe.weights import *\n",
    "from Axes.models import *\n",
    "from Axes.projection_functions import *\n",
    "from Axes.axes_definition import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Polarization log odds ratio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_1 = \"Lab\"\n",
    "party_2 = \"Con\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_partisanship = []\n",
    "\n",
    "for i in range(10):\n",
    "    df = standard_opening(\n",
    "            \"data/FinalDataframes/FilteredFinalDataFrame_201\" + str(i) + \".csv\", True\n",
    "        )\n",
    "    df = df[df[\"source\"] == \"par\"]\n",
    "    year = eval(\"201\" + str(i))\n",
    "    partisanship_matrix, idx2words, words2idx = get_word_partisanship(df, year, party_1, party_2)\n",
    "    deltas = partisanship_matrix[3, :]\n",
    "    words = np.array(list(idx2words.values()), dtype=None)\n",
    "    df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "    dfs_partisanship.append(df_sorted_partisanships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_1 = \"Lab\"\n",
    "party_2 = \"Con\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_partisanship = []\n",
    "\n",
    "for i in range(10):\n",
    "    df = standard_opening(\n",
    "            \"data/FinalDataframes/FilteredFinalDataFrame_201\" + str(i) + \".csv\", True\n",
    "        )\n",
    "    df = df[df[\"source\"] == \"par\"]\n",
    "    year = eval(\"201\" + str(i))\n",
    "    partisanship_matrix, idx2words, words2idx = get_word_partisanship(df, year, party_1, party_2, bigram=True)\n",
    "    deltas = partisanship_matrix[3, :]\n",
    "    words = np.array(list(idx2words.values()), dtype=None)\n",
    "    df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "    dfs_partisanship.append(df_sorted_partisanships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Combine with embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_with_axis_word(word: str, b,  model_words) :   \n",
    "\n",
    "    array_1 = model_words[word]\n",
    "    array_2 = b\n",
    "\n",
    "    cosine = np.dot(array_1, array_2.T) / (norm(array_1) * norm(array_2))\n",
    "\n",
    "    return cosine\n",
    "\n",
    "def cosine_with_axis_bigram(bigram: str, b,  model_words) :   \n",
    "\n",
    "    word_1, word_2 = bigram.split(' ')\n",
    "\n",
    "    array_1 = (model_words[word_1] + model_words[word_2]) * 0.5\n",
    "    array_2 = b\n",
    "\n",
    "    cosine = np.dot(array_1, array_2.T) / (norm(array_1) * norm(array_2))\n",
    "\n",
    "    return cosine\n",
    "\n",
    "def get_quantiles(data, percentiles):\n",
    "    \"\"\"\n",
    "    Get quantiles from a distribution.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The data.\n",
    "        percentiles (array-like): The percentiles to compute (0-100).\n",
    "    \n",
    "    Returns:\n",
    "        quantiles (array): The values at the specified percentiles.\n",
    "    \"\"\"\n",
    "    return np.percentile(data, percentiles)\n",
    "\n",
    "def filter_deltas(df, delta_low_percentile, delta_high_percentile, cos_low_percentile, cos_high_percentile):\n",
    "    delta_percentiles = [delta_low_percentile, delta_high_percentile]\n",
    "    cos_percentiles = [cos_low_percentile, cos_high_percentile]\n",
    "\n",
    "    quantiles_deltas = get_quantiles(df['deltas'], delta_percentiles)\n",
    "    quantiles_cos = get_quantiles(df['cos'], cos_percentiles)\n",
    "\n",
    "    df = df.loc[(df['deltas'] < quantiles_deltas[0]) | (df['deltas'] > quantiles_deltas[1])]\n",
    "    df = df.loc[(df['cos'] < quantiles_cos[0]) | (df['cos'] > quantiles_cos[1])]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10) :\n",
    "\n",
    "    df = dfs_partisanship[i]\n",
    "    m = models_w[i]\n",
    "    pos_a = filter_model(pos_1, m)\n",
    "    neg_a = filter_model(neg_1, m)\n",
    "\n",
    "    b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "    df['cos'] = df['words'].apply(cosine_with_axis_word, b=b, model_words=m)\n",
    "    dfs_partisanship[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10) :\n",
    "\n",
    "    df = dfs_partisanship[i]\n",
    "    m = models_w[i]\n",
    "    pos_a = filter_model(pos_1, m)\n",
    "    neg_a = filter_model(neg_1, m)\n",
    "\n",
    "    b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "    df['cos'] = df['words'].apply(cosine_with_axis_bigram, b=b, model_words=m)\n",
    "    dfs_partisanship[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs_partisanship[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>deltas</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10964</th>\n",
       "      <td>amazon</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.209501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>amazoncom</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13254</th>\n",
       "      <td>amazonian</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>amazoncouk</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>amazonbest</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12992</th>\n",
       "      <td>amazonamazon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>dealamazon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7288</th>\n",
       "      <td>amazonfresh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8432</th>\n",
       "      <td>saidamazon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>amazonth</td>\n",
       "      <td>-0.824044</td>\n",
       "      <td>0.022417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words    deltas       cos\n",
       "10964        amazon  0.007254  0.209501\n",
       "3526      amazoncom  0.000000  0.141262\n",
       "13254     amazonian  0.000000  0.166705\n",
       "12360    amazoncouk  0.000000  0.199117\n",
       "2607     amazonbest  0.000000  0.178672\n",
       "12992  amazonamazon  0.000000  0.201914\n",
       "1828     dealamazon  0.000000  0.385852\n",
       "7288    amazonfresh  0.000000  0.143035\n",
       "8432     saidamazon  0.000000  0.070523\n",
       "11516      amazonth -0.824044  0.022417"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['words'].str.contains('amazon')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_deltas(df, 10, 90, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>deltas</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>scottish give</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>-0.119336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>regim howev</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>-0.189289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>within social</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.061350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>prefer follow</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>subsidiari part</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.026633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15921</th>\n",
       "      <td>biggest democrat</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.144424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16109</th>\n",
       "      <td>alik deliv</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.039942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>allow dealer</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.029463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12574</th>\n",
       "      <td>announc lastli</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.005192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>wrist struck</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.081348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11197</th>\n",
       "      <td>postbrexit legisl</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.267026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19405</th>\n",
       "      <td>organis everybodi</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>unless lengthi</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.141821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14085</th>\n",
       "      <td>buse pleasant</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.156870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15294</th>\n",
       "      <td>domest appropri</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.326790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>fulltim franchis</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18800</th>\n",
       "      <td>selfcar relat</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.250416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13494</th>\n",
       "      <td>infrequ provis</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.207287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>call bass</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.108509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>press burma</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.066298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>shelter london</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.043616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>plan stcenturi</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.028350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12139</th>\n",
       "      <td>repres justic</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.041032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10842</th>\n",
       "      <td>mani intens</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.055518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>kill report</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>-0.069138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>research midland</td>\n",
       "      <td>0.638231</td>\n",
       "      <td>0.096579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>look posit</td>\n",
       "      <td>0.330699</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>given constitu</td>\n",
       "      <td>0.291475</td>\n",
       "      <td>-0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>recycl rate</td>\n",
       "      <td>0.180402</td>\n",
       "      <td>-0.106917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>assur commun</td>\n",
       "      <td>0.167574</td>\n",
       "      <td>-0.110624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>case despit</td>\n",
       "      <td>0.079688</td>\n",
       "      <td>-0.039386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18617</th>\n",
       "      <td>like increas</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>0.030724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>abroad understand</td>\n",
       "      <td>-0.059189</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11393</th>\n",
       "      <td>rather favour</td>\n",
       "      <td>-0.059189</td>\n",
       "      <td>-0.009389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15955</th>\n",
       "      <td>live wife</td>\n",
       "      <td>-0.059189</td>\n",
       "      <td>0.120651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14107</th>\n",
       "      <td>labour requir</td>\n",
       "      <td>-0.286657</td>\n",
       "      <td>-0.179921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>less money</td>\n",
       "      <td>-0.312872</td>\n",
       "      <td>0.064059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>howev ignor</td>\n",
       "      <td>-0.404363</td>\n",
       "      <td>-0.056808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17990</th>\n",
       "      <td>personnel ministeri</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>-0.115275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14025</th>\n",
       "      <td>abus echo</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.094830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3319</th>\n",
       "      <td>drawn secret</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.037741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16813</th>\n",
       "      <td>seen weak</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>-0.032505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>junior team</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.058632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18762</th>\n",
       "      <td>back deeper</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.227023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>accord hansard</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.013677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>tear afterward</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.100732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9454</th>\n",
       "      <td>extens compar</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.001437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>complet regardless</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.017979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13284</th>\n",
       "      <td>afterward revisit</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>-0.045136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>give contractor</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>-0.066621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16530</th>\n",
       "      <td>export share</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.084869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>show guarante</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.037910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>good german</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.078588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "      <td>argu american</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.063619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>sleeper quickli</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>0.084506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11403</th>\n",
       "      <td>numer autumn</td>\n",
       "      <td>-0.755913</td>\n",
       "      <td>-0.089994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>least needi</td>\n",
       "      <td>-0.760233</td>\n",
       "      <td>-0.047321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7246</th>\n",
       "      <td>term without</td>\n",
       "      <td>-0.760233</td>\n",
       "      <td>-0.073505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     words    deltas       cos\n",
       "9994         scottish give  0.641854 -0.119336\n",
       "2376           regim howev  0.641854 -0.189289\n",
       "9730         within social  0.638231 -0.061350\n",
       "12791        prefer follow  0.638231  0.008373\n",
       "13092      subsidiari part  0.638231  0.026633\n",
       "15921     biggest democrat  0.638231  0.144424\n",
       "16109           alik deliv  0.638231  0.039942\n",
       "5873          allow dealer  0.638231  0.029463\n",
       "12574       announc lastli  0.638231 -0.005192\n",
       "18950         wrist struck  0.638231 -0.081348\n",
       "11197    postbrexit legisl  0.638231 -0.267026\n",
       "19405    organis everybodi  0.638231 -0.001840\n",
       "15317       unless lengthi  0.638231 -0.141821\n",
       "14085        buse pleasant  0.638231  0.156870\n",
       "15294      domest appropri  0.638231 -0.326790\n",
       "2261      fulltim franchis  0.638231  0.013489\n",
       "18800        selfcar relat  0.638231 -0.250416\n",
       "13494       infrequ provis  0.638231 -0.207287\n",
       "864              call bass  0.638231  0.108509\n",
       "14720          press burma  0.638231 -0.066298\n",
       "10603       shelter london  0.638231  0.043616\n",
       "9946        plan stcenturi  0.638231  0.028350\n",
       "12139        repres justic  0.638231 -0.041032\n",
       "10842          mani intens  0.638231  0.055518\n",
       "140            kill report  0.638231 -0.069138\n",
       "18340     research midland  0.638231  0.096579\n",
       "3248            look posit  0.330699  0.002260\n",
       "1153        given constitu  0.291475 -0.035573\n",
       "11454          recycl rate  0.180402 -0.106917\n",
       "17291         assur commun  0.167574 -0.110624\n",
       "7170           case despit  0.079688 -0.039386\n",
       "18617         like increas  0.040094  0.030724\n",
       "12425    abroad understand -0.059189  0.007615\n",
       "11393        rather favour -0.059189 -0.009389\n",
       "15955            live wife -0.059189  0.120651\n",
       "14107        labour requir -0.286657 -0.179921\n",
       "17123           less money -0.312872  0.064059\n",
       "2377           howev ignor -0.404363 -0.056808\n",
       "17990  personnel ministeri -0.755913 -0.115275\n",
       "14025            abus echo -0.755913  0.094830\n",
       "3319          drawn secret -0.755913  0.037741\n",
       "16813            seen weak -0.755913 -0.032505\n",
       "15777          junior team -0.755913  0.058632\n",
       "18762          back deeper -0.755913  0.227023\n",
       "366         accord hansard -0.755913  0.013677\n",
       "13283       tear afterward -0.755913  0.100732\n",
       "9454         extens compar -0.755913  0.001437\n",
       "6595    complet regardless -0.755913  0.017979\n",
       "13284    afterward revisit -0.755913 -0.045136\n",
       "9995       give contractor -0.755913 -0.066621\n",
       "16530         export share -0.755913  0.084869\n",
       "15808        show guarante -0.755913  0.037910\n",
       "5573           good german -0.755913  0.078588\n",
       "17355        argu american -0.755913  0.063619\n",
       "9129       sleeper quickli -0.755913  0.084506\n",
       "11403         numer autumn -0.755913 -0.089994\n",
       "15689          least needi -0.760233 -0.047321\n",
       "7246          term without -0.760233 -0.073505"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='deltas', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Define polarization from embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Polarization as topic embeddings cosine distance**\n",
    "https://doi.org/10.48550/arXiv.2104.07814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
