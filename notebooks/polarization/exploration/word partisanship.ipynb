{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alexandrequeant/Desktop/Travail-TSE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../../..\")\n",
    "os.chdir(r\"src\")\n",
    "\n",
    "from Polarization.word_partisanship import *\n",
    "from GloVe.weights import *\n",
    "from Axes.projection_functions import *\n",
    "from Axes.axes_definition import *\n",
    "from Axes.models import *\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Polarization log odds ratio**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_1 = \"Lab\"\n",
    "party_2 = \"Con\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_partisanship = []\n",
    "\n",
    "for i in range(10):\n",
    "    df = standard_opening(\n",
    "            \"data/FinalDataframes/FilteredFinalDataFrame_201\" + str(i) + \".csv\", True\n",
    "        )\n",
    "    df = df[df[\"source\"] == \"par\"]\n",
    "    year = eval(\"201\" + str(i))\n",
    "    partisanship_matrix, idx2words, words2idx = get_word_partisanship(df, year, party_1, party_2)\n",
    "    deltas = partisanship_matrix[3, :]\n",
    "    words = np.array(list(idx2words.values()), dtype=None)\n",
    "    df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "    dfs_partisanship.append(df_sorted_partisanships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>curlew</td>\n",
       "      <td>0.562265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14111</th>\n",
       "      <td>primat</td>\n",
       "      <td>0.562261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5799</th>\n",
       "      <td>quarri</td>\n",
       "      <td>0.562261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>veolia</td>\n",
       "      <td>0.562261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9855</th>\n",
       "      <td>torr</td>\n",
       "      <td>0.562260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11136</th>\n",
       "      <td>bach</td>\n",
       "      <td>-0.824050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12667</th>\n",
       "      <td>karim</td>\n",
       "      <td>-0.824050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>threadbar</td>\n",
       "      <td>-0.824050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>superrich</td>\n",
       "      <td>-0.824051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>doherti</td>\n",
       "      <td>-0.824051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19492 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words    deltas\n",
       "12749     curlew  0.562265\n",
       "14111     primat  0.562261\n",
       "5799      quarri  0.562261\n",
       "419       veolia  0.562261\n",
       "9855        torr  0.562260\n",
       "...          ...       ...\n",
       "11136       bach -0.824050\n",
       "12667      karim -0.824050\n",
       "9494   threadbar -0.824050\n",
       "9741   superrich -0.824051\n",
       "3218     doherti -0.824051\n",
       "\n",
       "[19492 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_partisanship[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_1 = \"Lab\"\n",
    "party_2 = \"Con\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_partisanship = []\n",
    "\n",
    "for i in range(10):\n",
    "    df = standard_opening(\n",
    "            \"data/FinalDataframes/FilteredFinalDataFrame_201\" + str(i) + \".csv\", True\n",
    "        )\n",
    "    df = df[df[\"source\"] == \"par\"]\n",
    "    year = eval(\"201\" + str(i))\n",
    "    partisanship_matrix, idx2words, words2idx = get_word_partisanship(df, year, party_1, party_2, bigram=True)\n",
    "    deltas = partisanship_matrix[3, :]\n",
    "    words = np.array(list(idx2words.values()), dtype=None)\n",
    "    df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "    dfs_partisanship.append(df_sorted_partisanships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Combine with embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_with_axis_word(word: str, b,  model_words) :   \n",
    "\n",
    "    array_1 = model_words[word]\n",
    "    array_2 = b\n",
    "\n",
    "    cosine = np.dot(array_1, array_2.T) / (norm(array_1) * norm(array_2))\n",
    "\n",
    "    return cosine\n",
    "\n",
    "def cosine_with_axis_bigram(bigram: str, b,  model_words) :   \n",
    "\n",
    "    word_1, word_2 = bigram.split(' ')\n",
    "\n",
    "    array_1 = (model_words[word_1] + model_words[word_2]) * 0.5\n",
    "    array_2 = b\n",
    "\n",
    "    cosine = np.dot(array_1, array_2.T) / (norm(array_1) * norm(array_2))\n",
    "\n",
    "    return cosine\n",
    "\n",
    "def get_quantiles(data, percentiles):\n",
    "    \"\"\"\n",
    "    Get quantiles from a distribution.\n",
    "    \n",
    "    Parameters:\n",
    "        data (array-like): The data.\n",
    "        percentiles (array-like): The percentiles to compute (0-100).\n",
    "    \n",
    "    Returns:\n",
    "        quantiles (array): The values at the specified percentiles.\n",
    "    \"\"\"\n",
    "    return np.percentile(data, percentiles)\n",
    "\n",
    "def filter_deltas(df, delta_low_percentile, delta_high_percentile):\n",
    "    delta_percentiles = [delta_low_percentile, delta_high_percentile]\n",
    "\n",
    "    quantiles_deltas = get_quantiles(df['deltas'], delta_percentiles)\n",
    "\n",
    "    df = df.loc[(df['deltas'] < quantiles_deltas[0]) | (df['deltas'] > quantiles_deltas[1])]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10) :\n",
    "\n",
    "    df = dfs_partisanship[i]\n",
    "    m = models_w[i]\n",
    "    pos_a = filter_model(pos_1, m)\n",
    "    neg_a = filter_model(neg_1, m)\n",
    "\n",
    "    b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "    df['cos'] = df['words'].apply(cosine_with_axis_word, b=b, model_words=m)\n",
    "    dfs_partisanship[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10) :\n",
    "\n",
    "    df = dfs_partisanship[i]\n",
    "    m = models_w[i]\n",
    "    pos_a = filter_model(pos_1, m)\n",
    "    neg_a = filter_model(neg_1, m)\n",
    "\n",
    "    b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "    df['cos'] = df['words'].apply(cosine_with_axis_bigram, b=b, model_words=m)\n",
    "    dfs_partisanship[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs_partisanship[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_deltas(df, 10, 90, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='deltas', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(models_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj = pd.read_csv(\"data/current_dataframes/df_BT\")\n",
    "year = 2017\n",
    "df_par = df_proj.loc[df_proj['year'] == year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantiles(data, percentiles):\n",
    "    \"\"\"\n",
    "    Compute quantiles for a given dataset and percentiles.\n",
    "    \n",
    "    :param data: Numerical data from which to calculate quantiles.\n",
    "    :param percentiles: A list of percentiles to calculate for the data.\n",
    "    :return: An array of quantiles corresponding to the specified percentiles.\n",
    "    \"\"\"\n",
    "    return np.percentile(data, percentiles)\n",
    "\n",
    "def partizan_words(left_side, right_side, year, gram = 'bigram', focus_on_companies=None, axis=None,\n",
    "    percentiles_cos=[10, 90], percentiles_delta=[10, 90], force_i_lim=None, re_filter_cos=False, percentiles_refiltering_cos = [25, 75]):\n",
    "\n",
    "    sources = left_side+right_side\n",
    "\n",
    "    s = str(year)[-2:]\n",
    "\n",
    "    if s[0] == '1':\n",
    "        i = eval(s[1])\n",
    "    if s[0] == '2':\n",
    "        i = eval('1'+s[1])\n",
    "    \n",
    "    df_proj = pd.read_csv(\"data/current_dataframes/df_BT\")\n",
    "\n",
    "    df_par = df_proj.loc[df_proj[\"source\"].isin(sources) | df_proj[\"party\"].isin(sources)]\n",
    "    \n",
    "    def change_year(old_year):\n",
    "        if int(old_year) == 20110:\n",
    "            return 2020\n",
    "        if int(old_year) == 20111:\n",
    "            return 2021\n",
    "        if int(old_year) == 20112:\n",
    "            return 2022\n",
    "        if int(old_year) == 20113:\n",
    "            return 2023\n",
    "        else :\n",
    "            return int(old_year)\n",
    "        \n",
    "    df_par['year'] = df_par['year'].apply(change_year)\n",
    "    df_par = df_par.loc[df_par['year'] == year]\n",
    "\n",
    "    df1 = df_par[df_par['source'] == 'par']\n",
    "    df2 = df_par[df_par['source'] != 'par']\n",
    "\n",
    "    # Define a function to translate newspaper source to party\n",
    "    def translate_party(newspaper):\n",
    "        \"\"\"\n",
    "        Translates newspaper sources to their corresponding political party.\n",
    "        \n",
    "        :param newspaper: The source to be translated.\n",
    "        :return: The political party corresponding to the source.\n",
    "        \"\"\"\n",
    "        if newspaper in left_side:\n",
    "            return \"Lab\"\n",
    "        if newspaper in right_side:\n",
    "            return \"Con\"\n",
    "    \n",
    "    # Apply the translation function to assign parties based on sources\n",
    "    df2['party'] = df2['source'].apply(translate_party)\n",
    "    df2['Speaker'] = range(len(df2))\n",
    "\n",
    "    # Combine the two DataFrames and reset index for continuity\n",
    "    df_par = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "\n",
    "    if focus_on_companies:\n",
    "        df_par = df_par.loc[df_par[\"class\"].isin(focus_on_companies)]\n",
    "\n",
    "    if axis is not None:\n",
    "        quantiles = get_quantiles(df_par[f'cos axe {axis}'], percentiles_cos)\n",
    "        df_par = df_par[(df_par[f'cos axe {axis}'] < quantiles[0]) | (df_par[f'cos axe {axis}'] > quantiles[1])]\n",
    "\n",
    "    def phrase_to_tokens(phrase):\n",
    "        word_list = phrase.strip(\"_\").split(\"_\")\n",
    "        return word_list\n",
    "    \n",
    "    df_par['text'] = df_par['text'].apply(phrase_to_tokens)\n",
    "\n",
    "    if gram == 'bigram' :\n",
    "        partisanship_matrix, idx2words, words2idx = get_word_partisanship(df_par, year, 'Lab', 'Con', bigram=True)\n",
    "        deltas = partisanship_matrix[3, :]\n",
    "        words = np.array(list(idx2words.values()), dtype=None)\n",
    "        df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "    \n",
    "\n",
    "        df = df_sorted_partisanships\n",
    "        m = models_w[i]\n",
    "        pos_a = filter_model(pos_1, m)\n",
    "        neg_a = filter_model(neg_1, m)\n",
    "\n",
    "        b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "        df['cos'] = df['words'].apply(cosine_with_axis_bigram, b=b, model_words=m)\n",
    "        df_sorted_partisanships = df\n",
    "        df = filter_deltas(df, percentiles_delta[0], percentiles_delta[1])\n",
    "\n",
    "    if gram == 'unigram' :\n",
    "        partisanship_matrix, idx2words, words2idx = get_word_partisanship(df_par, year, 'Lab', 'Con', bigram=False)\n",
    "        deltas = partisanship_matrix[3, :]\n",
    "        words = np.array(list(idx2words.values()), dtype=None)\n",
    "        df_sorted_partisanships = pd.DataFrame({'words' : words, 'deltas' : deltas}).sort_values(by='deltas', ascending=False)\n",
    "        \n",
    "        df = df_sorted_partisanships\n",
    "        m = models_w[i]\n",
    "        pos_a = filter_model(pos_1, m)\n",
    "        neg_a = filter_model(neg_1, m)\n",
    "\n",
    "        b = barycentre(pos_a, m) - barycentre(neg_a, m)\n",
    "        df['cos'] = df['words'].apply(cosine_with_axis_word, b=b, model_words=m)\n",
    "        df_sorted_partisanships = df\n",
    "        df = filter_deltas(df, percentiles_delta[0], percentiles_delta[1])\n",
    "\n",
    "    if re_filter_cos:\n",
    "        quantiles = get_quantiles(df['cos'], percentiles_refiltering_cos)\n",
    "        df = df[(df['cos'] < quantiles[0]) | (df['cos'] > quantiles[1])]\n",
    "\n",
    "    return df.sort_values(by='deltas', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0                                               text  \\\n",
      "2153        78.0  [absolut, heart, point, make, peopl, need, tim...   \n",
      "2154        97.0  [tribut, work, sixthform, educ, fantast, work,...   \n",
      "2155       106.0  [much, welcom, comment, absolut, metaphor, nee...   \n",
      "2156       170.0  [permiss, would, like, make, statement, polit,...   \n",
      "2157       282.0  [longer, term, peopl, consum, less, sugar, thi...   \n",
      "...          ...                                                ...   \n",
      "5206     22232.0  [honour, serv, join, choru, welldeserv, congra...   \n",
      "5207     22236.0  [concur, comment, absolut, right, mere, word, ...   \n",
      "5208     22243.0  [certainli, appli, case, good, point, remain, ...   \n",
      "5209     22247.0  [make, interest, suggest, take, away, come, ba...   \n",
      "5210     22248.0  [grate, debat, thank, respond, mani, point, ma...   \n",
      "\n",
      "                                     sentence_embedding source party  \\\n",
      "2153  ['-0.03473206079978031', '0.05706717554553675'...    par   Con   \n",
      "2154  ['-0.010494572082950737', '0.12201923353880761...    par   Lab   \n",
      "2155  ['-0.11845861713116057', '0.16144335319586758'...    par   Lab   \n",
      "2156  ['-0.08488949235300872', '0.0611561592413043',...    par   Con   \n",
      "2157  ['-0.0970514345815155', '0.04569097751550988',...    par   Lab   \n",
      "...                                                 ...    ...   ...   \n",
      "5206  ['-0.05136332744119265', '0.057299403546522354...    par   Con   \n",
      "5207  ['-0.00766624787557485', '0.13712094695088783'...    par   Lab   \n",
      "5208  ['-0.00655366602098606', '-0.03295887848219703...    par   Lab   \n",
      "5209  ['-0.07156727820227793', '-0.07146490802827787...    par   Con   \n",
      "5210  ['-0.0690327699423223', '-0.041587313989454255...    par   Con   \n",
      "\n",
      "                              keywords            Speaker  year  cos axe 1  \\\n",
      "2153          ['jobs', 'meta', 'brin']   Justin Tomlinson  2017   0.129717   \n",
      "2154                 ['meta', 'excel']     Nicholas Dakin  2017   0.008143   \n",
      "2155                          ['meta']     Nicholas Dakin  2017  -0.109365   \n",
      "2156                  ['meta', 'brin']  James Brokenshire  2017  -0.234960   \n",
      "2157                          ['meta']          Mike Kane  2017  -0.105966   \n",
      "...                                ...                ...   ...        ...   \n",
      "5206                           ['ios']      Robert Courts  2017   0.027459   \n",
      "5207                          ['jobs']       Ruth Cadbury  2017   0.139995   \n",
      "5208  ['cook', 'meta', 'nest', 'brin']        John Healey  2017  -0.296102   \n",
      "5209          ['cook', 'nest', 'brin']        Alok Sharma  2017  -0.342870   \n",
      "5210         ['watch', 'brin', 'edge']    Peter Bottomley  2017  -0.242476   \n",
      "\n",
      "      cos axe 2                             theme class  \n",
      "2153   0.212550   ['apple', 'facebook', 'google']    fb  \n",
      "2154   0.081669         ['facebook', 'microsoft']    fb  \n",
      "2155   0.164981                      ['facebook']    fb  \n",
      "2156   0.107292            ['facebook', 'google']    fb  \n",
      "2157   0.198921                      ['facebook']    fb  \n",
      "...         ...                               ...   ...  \n",
      "5206   0.009499                         ['apple']    ap  \n",
      "5207  -0.056073                         ['apple']    ap  \n",
      "5208  -0.121326   ['apple', 'facebook', 'google']    ap  \n",
      "5209   0.064555               ['apple', 'google']    ap  \n",
      "5210  -0.105635  ['apple', 'microsoft', 'google']    ap  \n",
      "\n",
      "[3058 rows x 12 columns]\n",
      "57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>deltas</th>\n",
       "      <th>cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>fulltim franchis</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.013489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>call bass</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.108509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>shelter london</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.043616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12791</th>\n",
       "      <td>prefer follow</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.008373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9946</th>\n",
       "      <td>plan stcenturi</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.028350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12425</th>\n",
       "      <td>abroad understand</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16109</th>\n",
       "      <td>alik deliv</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>0.039942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>wrist struck</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>-0.081348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17291</th>\n",
       "      <td>assur commun</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>-0.110624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14720</th>\n",
       "      <td>press burma</td>\n",
       "      <td>0.741466</td>\n",
       "      <td>-0.066298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>look posit</td>\n",
       "      <td>0.422547</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18617</th>\n",
       "      <td>like increas</td>\n",
       "      <td>0.361790</td>\n",
       "      <td>0.030724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>recycl rate</td>\n",
       "      <td>0.128766</td>\n",
       "      <td>-0.106917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>given constitu</td>\n",
       "      <td>0.040410</td>\n",
       "      <td>-0.035573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15955</th>\n",
       "      <td>live wife</td>\n",
       "      <td>0.039221</td>\n",
       "      <td>0.120651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>case despit</td>\n",
       "      <td>-0.316270</td>\n",
       "      <td>-0.039386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>less money</td>\n",
       "      <td>-0.316681</td>\n",
       "      <td>0.064059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>good german</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.078588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>sleeper quickli</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.084506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "      <td>argu american</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.063619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>howev ignor</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>-0.056808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16530</th>\n",
       "      <td>export share</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.084869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11403</th>\n",
       "      <td>numer autumn</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>-0.089994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>show guarante</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.037910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17990</th>\n",
       "      <td>personnel ministeri</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>-0.115275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7246</th>\n",
       "      <td>term without</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>-0.073505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15777</th>\n",
       "      <td>junior team</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.058632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>accord hansard</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.013677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13283</th>\n",
       "      <td>tear afterward</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>0.100732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16813</th>\n",
       "      <td>seen weak</td>\n",
       "      <td>-0.664160</td>\n",
       "      <td>-0.032505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>least needi</td>\n",
       "      <td>-0.673539</td>\n",
       "      <td>-0.047321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     words    deltas       cos\n",
       "2261      fulltim franchis  0.741466  0.013489\n",
       "864              call bass  0.741466  0.108509\n",
       "10603       shelter london  0.741466  0.043616\n",
       "12791        prefer follow  0.741466  0.008373\n",
       "9946        plan stcenturi  0.741466  0.028350\n",
       "12425    abroad understand  0.741466  0.007615\n",
       "16109           alik deliv  0.741466  0.039942\n",
       "18950         wrist struck  0.741466 -0.081348\n",
       "17291         assur commun  0.741466 -0.110624\n",
       "14720          press burma  0.741466 -0.066298\n",
       "3248            look posit  0.422547  0.002260\n",
       "18617         like increas  0.361790  0.030724\n",
       "11454          recycl rate  0.128766 -0.106917\n",
       "1153        given constitu  0.040410 -0.035573\n",
       "15955            live wife  0.039221  0.120651\n",
       "7170           case despit -0.316270 -0.039386\n",
       "17123           less money -0.316681  0.064059\n",
       "5573           good german -0.664160  0.078588\n",
       "9129       sleeper quickli -0.664160  0.084506\n",
       "17355        argu american -0.664160  0.063619\n",
       "2377           howev ignor -0.664160 -0.056808\n",
       "16530         export share -0.664160  0.084869\n",
       "11403         numer autumn -0.664160 -0.089994\n",
       "15808        show guarante -0.664160  0.037910\n",
       "17990  personnel ministeri -0.664160 -0.115275\n",
       "7246          term without -0.664160 -0.073505\n",
       "15777          junior team -0.664160  0.058632\n",
       "366         accord hansard -0.664160  0.013677\n",
       "13283       tear afterward -0.664160  0.100732\n",
       "16813            seen weak -0.664160 -0.032505\n",
       "15689          least needi -0.673539 -0.047321"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partizan_words(['Lab'], ['Con'], 2017, focus_on_companies=['fb', 'ap'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
