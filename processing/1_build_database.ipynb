{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.chdir(r\"src\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Processing.preprocess_parliament import *\n",
    "\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_par = read_HouseOfCommons(keep_date=True, rd_lines=False, size=100)\n",
    "df_DM = pd.read_csv('data/raw_corpuses/articlesDM.csv', index_col=[0])\n",
    "df_DE = pd.read_csv('data/raw_corpuses/articlesDE.csv', index_col=[0])\n",
    "df_GUA = pd.read_csv('data/raw_corpuses/articlesGUA.csv', index_col=[0])\n",
    "df_MET = pd.read_csv('data/raw_corpuses/articlesMET.csv', index_col=[0])\n",
    "df_TE = pd.read_csv('data/raw_corpuses/articlesTE.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dates**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create here a function that finds the date of publication from some newspapers' urls, as we didn't get it by the webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_date_url(url:str):\n",
    "    for i in range(14):\n",
    "        if str(2010+i) in url :\n",
    "            return str(2010+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MET['date'] = df_MET['url'].apply(find_date_url)\n",
    "df_GUA['date'] = df_GUA['url'].apply(find_date_url)\n",
    "df_TE['date'] = df_TE['url'].apply(find_date_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_date(date):\n",
    "    try :\n",
    "        return(date[:4])\n",
    "    except :\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DM['date'] = df_DM['date'].apply(cut_date)\n",
    "df_DE['date'] = df_DE['date'].apply(cut_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parliament database filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par['date'] = df_par['date'].apply(cut_date)\n",
    "df_par = df_par.rename(columns={'date':'year'})\n",
    "df_par['source'] = 'par'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_stem_topics = process_list_BigTech_words(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexandrequeant/Desktop/Stage Toulouse /Stage_TSE_2023/Stage_TSE_2023/src/preprocess_parliament.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['agenda', 'lines_to_keep'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_par = keep_Bigtech_speeches(df_par, list_stem_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_par.reset_index(inplace=True)\n",
    "df_par.to_csv('df_par.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We format all the dataframes to have the same relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DM = df_DM[['date', 'fulltext', 'headline', 'url']]\n",
    "df_DM = df_DM.rename(columns={\"fulltext\": \"text\", \"date\": \"year\", \"headline\":\"agenda\"})\n",
    "df_DM['source'] = 'DM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_DE = df_DE[['date', 'fulltext', 'headline', 'url']]\n",
    "df_DE = df_DE.rename(columns={\"fulltext\": \"text\", \"date\": \"year\", \"headline\":\"agenda\"})\n",
    "df_DE['source'] = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GUA = df_GUA[['date', 'fulltext', 'summary', 'url']]\n",
    "df_GUA = df_GUA.rename(columns={\"fulltext\": \"text\", \"date\": \"year\", \"summary\":\"agenda\"})\n",
    "df_GUA['source'] = 'GUA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MET = df_MET[['date', 'fulltext', 'headline', 'url']]\n",
    "df_MET= df_MET.rename(columns={\"fulltext\": \"text\", \"date\": \"year\", \"headline\":\"agenda\"})\n",
    "df_MET['source'] = 'MET'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TE = df_TE[['date', 'fulltext', 'headline', 'url']]\n",
    "df_TE= df_TE.rename(columns={\"fulltext\": \"text\", \"date\": \"year\", \"headline\":\"agenda\"})\n",
    "df_TE['source'] = 'TE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Retrofiltering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We study here the urls of our articles in order to save for which keywords they have been selected during the webscraping phase. We can then use it in order to filter articles by keywords during our study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = ['apple', 'iphone', 'ipad', 'mac', 'watch', 'macbook', 'ios', 'airpods', 'app-store', 'itunes', 'icloud', 'beats', 'siri', 'shazam', 'cook', 'jobs', 'meta', 'facebook', 'messenger', 'instagram', 'oculus', 'whatsApp', 'zuckerberg', 'olivan', 'clegg', 'social-media', 'amazon', 'prime', 'whole-foods', 'zappos', 'pillpack', 'twitch', 'audible', 'goodreads', 'imdb', 'bezos', 'jassy', 'olsavsky', 'alexander', 'google', 'android', 'chrome', 'gmail', 'maps', 'playstore', 'pixel', 'waze', 'youtube', 'alphabet', 'mandiant', 'fitbit', 'looker', 'nest', 'doubleclick', 'page', 'brin', 'pichai', 'kurian', 'microsoft', 'windows', 'cortana', 'excel', 'explorer', 'edge', 'teams', 'outlook', 'powerpoint', 'skype', 'surface', 'xbox', 'linkedIn', 'github', 'mojang', 'gates', 'nadella', 'gafa', 'gafam', 'big-tech', 'consumer-privacy', 'tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retro_filt_speech(speech):\n",
    "    l = []\n",
    "    for word in key_words:\n",
    "        if word in str(speech.lower()):\n",
    "            l.append(word)\n",
    "    return l\n",
    "\n",
    "df_par['keywords'] = df_par['text'].apply(retro_filt_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retro_filt_url(url):\n",
    "    l = []\n",
    "    for word in key_words:\n",
    "        if word in str(url):\n",
    "            l.append(word)\n",
    "    return l\n",
    "\n",
    "df_DE['keywords'] = df_DE['url'].apply(retro_filt_url)\n",
    "df_DM['keywords'] = df_DM['url'].apply(retro_filt_url)\n",
    "df_GUA['keywords'] = df_GUA['url'].apply(retro_filt_url)\n",
    "df_TE['keywords'] = df_TE['url'].apply(retro_filt_url)\n",
    "df_MET['keywords'] = df_MET['url'].apply(retro_filt_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have here a loop to attibute a relevant date to articles that still miss one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(24):\n",
    "    for i in df_TE.index:\n",
    "        if df_TE['year'][i] == None :\n",
    "                try :\n",
    "                    df_TE['year'][i] = df_TE['year'][i+1]\n",
    "                except :\n",
    "                    i = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TE = df_TE.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_GUA, df_DE, df_DM, df_MET, df_TE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_par, df_GUA, df_DE, df_DM, df_MET, df_TE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intermediate dataframe appears here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then clean the dataframe and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cleen les titres des speechs\n",
    "df['agenda'] = df['agenda'].apply(clean, args=('unigram',))\n",
    "#On nettoie le texte des speeches \n",
    "df['text'] = df['text'].apply(clean, args=('unigram',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alexandrequeant/Desktop/Travail-TSE'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/without parliament/FinalDataframes/FinalDataFrame_WP.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59842"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
